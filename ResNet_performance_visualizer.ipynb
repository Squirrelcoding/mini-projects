{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNu6XmOE1MwYaM4IeWlrwzU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e711b7b587bf4dcb86440e64ad603597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fe994f5622f45168c15eb53b849e749",
              "IPY_MODEL_25d9c03484f749b8a570ca12aef9b6c4",
              "IPY_MODEL_69f12f548f8e4eeead9ac082a1452c40"
            ],
            "layout": "IPY_MODEL_d1ca2ad95ac64edda90491d62a213060"
          }
        },
        "6fe994f5622f45168c15eb53b849e749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_155255fa65e44f50a1aed25778b20933",
            "placeholder": "​",
            "style": "IPY_MODEL_d7f94f02117542b1a62d32eba9826bef",
            "value": "  5%"
          }
        },
        "25d9c03484f749b8a570ca12aef9b6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f80b12cfed744c4bf27840d7b787610",
            "max": 120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b419b5ddb2e4c7484907a4c5dd23100",
            "value": 6
          }
        },
        "69f12f548f8e4eeead9ac082a1452c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed6b1596ad094870a2436d89e59a683b",
            "placeholder": "​",
            "style": "IPY_MODEL_2dc2da9cb3c94a4381bc9580788fe744",
            "value": " 6/120 [05:01&lt;1:35:16, 50.15s/it]"
          }
        },
        "d1ca2ad95ac64edda90491d62a213060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "155255fa65e44f50a1aed25778b20933": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7f94f02117542b1a62d32eba9826bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f80b12cfed744c4bf27840d7b787610": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b419b5ddb2e4c7484907a4c5dd23100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed6b1596ad094870a2436d89e59a683b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dc2da9cb3c94a4381bc9580788fe744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Squirrelcoding/mini-projects/blob/main/ResNet_performance_visualizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "5Z8hruspkEOU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD4fCi87y1qr",
        "outputId": "c1dcdf0a-79f0-4ff9-dda0-d2c3c1dfb0f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "tcPBvPEhy4S3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "vEqzJM_ZyPgn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  # Note: you need the \"raw\" GitHub URL for this to work\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsW127zAxXDY",
        "outputId": "028e0f73-ebf8-4ecd-98df-981cabad82b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "helper_functions.py already exists, skipping download\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "# !unzip -q tiny-imagenet-200.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82QffnlIcP51",
        "outputId": "25593106-11fd-4aae-802d-b684057557d9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2025-08-07 23:12:20--  https://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
            "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.64.64\n",
            "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.64.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248100043 (237M) [application/zip]\n",
            "Saving to: ‘tiny-imagenet-200.zip.1’\n",
            "\n",
            "tiny-imagenet-200.z  12%[=>                  ]  28.41M  7.77MB/s    eta 27s    ^C\n",
            "replace tiny-imagenet-200/words.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "print(f\"Train size: {len(mnist_train)}\")\n",
        "print(f\"Test size: {len(mnist_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2k6YSYF3Qba",
        "outputId": "f4b7e6fc-63f7-46cb-9652-71f9d857e7c3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 60000\n",
            "Test size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "  def __init__(self, channels: int, out_channels: int, downsampling=False) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    stride = 2 if downsampling else 1\n",
        "\n",
        "    self.channels = channels\n",
        "    # First convolutional layer. If downsampling, we set the stride to 2.\n",
        "    self.conv1 = nn.Conv2d(channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "    # batch normalization\n",
        "    self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
        "    # ReLU. Not really necessary but helps with keeping track of stuff.\n",
        "    self.relu1 = nn.ReLU()\n",
        "    # second convolutional layer that increases channels if downsampling\n",
        "    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "    # batch normalization\n",
        "    self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
        "    self.relu2 = nn.ReLU()\n",
        "\n",
        "    self.downsampling = None\n",
        "    if downsampling:\n",
        "      # double the channels to keep time complexity of layers while halving the input\n",
        "      self.downsampling = nn.Sequential(nn.Conv2d(in_channels=self.channels,\n",
        "                                    out_channels=self.channels * 2,\n",
        "                                    kernel_size=1,\n",
        "                                    padding=0,\n",
        "                                    stride=2), nn.BatchNorm2d(num_features=out_channels))\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_copy = x\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "\n",
        "    # downsample stuff to match dimensions of x and x_copy\n",
        "    if self.downsampling:\n",
        "      x_copy = self.downsampling(x_copy)\n",
        "\n",
        "    x = x + x_copy\n",
        "    x = self.relu2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "9fZB6orcHGgj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class ResNet18(nn.Module):\n",
        "  def __init__(self, in_channels: int) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "    # Deepnet part\n",
        "    self.conv1 = nn.Conv2d(in_channels, out_channels=64, stride=2, kernel_size=7, padding=1)\n",
        "    self.conv10 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    self.conv2_1 = BasicBlock(64, 64)\n",
        "    self.conv2_2 = BasicBlock(64, 64)\n",
        "    self.conv3_1 = BasicBlock(64, 128, downsampling=True)\n",
        "    self.conv3_2 = BasicBlock(128, 128)\n",
        "    self.conv4_1 = BasicBlock(128,256, downsampling=True)\n",
        "    self.conv4_2 = BasicBlock(256, 256)\n",
        "    self.conv5_1 = BasicBlock(256, 512, downsampling=True)\n",
        "    self.conv5_2 = BasicBlock(512, 512)\n",
        "\n",
        "    # Classification head\n",
        "\n",
        "    # Average pooling\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "    self.fc_layer = nn.Linear(512, 200)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv10(x)\n",
        "    x = self.conv2_1(x)\n",
        "    x = self.conv2_2(x)\n",
        "    x = self.conv3_1(x)\n",
        "    x = self.conv3_2(x)\n",
        "    x = self.conv4_1(x)\n",
        "    x = self.conv4_2(x)\n",
        "    x = self.conv5_1(x)\n",
        "    x = self.conv5_2(x)\n",
        "\n",
        "    x = self.avg_pool(x)\n",
        "\n",
        "    x = torch.flatten(x, 1)\n",
        "\n",
        "    x = self.fc_layer(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "5nWQV0evlzWA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "\n",
        "model = ResNet18(in_channels=3).to(device)\n"
      ],
      "metadata": {
        "id": "7i0NzsclAVye"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def find_classes(root_dir: str):\n",
        "  folder_classes = {}\n",
        "  for i, folder in enumerate(os.listdir(root_dir)):\n",
        "    folder_classes[folder] = i\n",
        "  return [x for x in folder_classes], folder_classes\n",
        "\n",
        "find_classes(\"tiny-imagenet-200/train\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_CokmTPsv-G",
        "outputId": "94c1dd93-2621-4fab-ac92-e9916e57d0af"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['n03584254',\n",
              "  'n04465501',\n",
              "  'n02793495',\n",
              "  'n03970156',\n",
              "  'n06596364',\n",
              "  'n02094433',\n",
              "  'n03026506',\n",
              "  'n03770439',\n",
              "  'n04149813',\n",
              "  'n03976657',\n",
              "  'n07695742',\n",
              "  'n03355925',\n",
              "  'n04501370',\n",
              "  'n02927161',\n",
              "  'n03649909',\n",
              "  'n04456115',\n",
              "  'n04133789',\n",
              "  'n03100240',\n",
              "  'n04398044',\n",
              "  'n03014705',\n",
              "  'n02814860',\n",
              "  'n03255030',\n",
              "  'n02917067',\n",
              "  'n02841315',\n",
              "  'n01644900',\n",
              "  'n04254777',\n",
              "  'n04376876',\n",
              "  'n03160309',\n",
              "  'n07711569',\n",
              "  'n04560804',\n",
              "  'n02730930',\n",
              "  'n02321529',\n",
              "  'n03617480',\n",
              "  'n02165456',\n",
              "  'n09193705',\n",
              "  'n02113799',\n",
              "  'n04532670',\n",
              "  'n02099601',\n",
              "  'n01768244',\n",
              "  'n04597913',\n",
              "  'n02815834',\n",
              "  'n02106662',\n",
              "  'n07614500',\n",
              "  'n02206856',\n",
              "  'n02843684',\n",
              "  'n07873807',\n",
              "  'n09256479',\n",
              "  'n02415577',\n",
              "  'n09428293',\n",
              "  'n02403003',\n",
              "  'n03637318',\n",
              "  'n02791270',\n",
              "  'n02950826',\n",
              "  'n07615774',\n",
              "  'n03977966',\n",
              "  'n02123045',\n",
              "  'n07749582',\n",
              "  'n02074367',\n",
              "  'n01784675',\n",
              "  'n02480495',\n",
              "  'n02909870',\n",
              "  'n07753592',\n",
              "  'n02948072',\n",
              "  'n02802426',\n",
              "  'n03447447',\n",
              "  'n02437312',\n",
              "  'n03400231',\n",
              "  'n02132136',\n",
              "  'n04487081',\n",
              "  'n01910747',\n",
              "  'n02124075',\n",
              "  'n02509815',\n",
              "  'n04265275',\n",
              "  'n02190166',\n",
              "  'n04562935',\n",
              "  'n02410509',\n",
              "  'n03424325',\n",
              "  'n04070727',\n",
              "  'n04259630',\n",
              "  'n03763968',\n",
              "  'n07715103',\n",
              "  'n04146614',\n",
              "  'n02129165',\n",
              "  'n03992509',\n",
              "  'n02906734',\n",
              "  'n03388043',\n",
              "  'n04023962',\n",
              "  'n03804744',\n",
              "  'n01774384',\n",
              "  'n03085013',\n",
              "  'n03179701',\n",
              "  'n01984695',\n",
              "  'n07734744',\n",
              "  'n02486410',\n",
              "  'n04285008',\n",
              "  'n03837869',\n",
              "  'n04251144',\n",
              "  'n04311004',\n",
              "  'n03201208',\n",
              "  'n01774750',\n",
              "  'n03854065',\n",
              "  'n02788148',\n",
              "  'n02808440',\n",
              "  'n03670208',\n",
              "  'n01855672',\n",
              "  'n01950731',\n",
              "  'n07583066',\n",
              "  'n03042490',\n",
              "  'n01917289',\n",
              "  'n02977058',\n",
              "  'n01742172',\n",
              "  'n01770393',\n",
              "  'n01983481',\n",
              "  'n02236044',\n",
              "  'n01443537',\n",
              "  'n02999410',\n",
              "  'n02233338',\n",
              "  'n02281406',\n",
              "  'n02814533',\n",
              "  'n02125311',\n",
              "  'n02883205',\n",
              "  'n03838899',\n",
              "  'n07920052',\n",
              "  'n03814639',\n",
              "  'n07747607',\n",
              "  'n03980874',\n",
              "  'n02666196',\n",
              "  'n03250847',\n",
              "  'n03404251',\n",
              "  'n02504458',\n",
              "  'n02099712',\n",
              "  'n02056570',\n",
              "  'n04356056',\n",
              "  'n03393912',\n",
              "  'n02058221',\n",
              "  'n09332890',\n",
              "  'n03089624',\n",
              "  'n04596742',\n",
              "  'n04179913',\n",
              "  'n03599486',\n",
              "  'n04399382',\n",
              "  'n01944390',\n",
              "  'n04067472',\n",
              "  'n02123394',\n",
              "  'n03983396',\n",
              "  'n01641577',\n",
              "  'n02823428',\n",
              "  'n12267677',\n",
              "  'n03902125',\n",
              "  'n03444034',\n",
              "  'n04118538',\n",
              "  'n04275548',\n",
              "  'n02769748',\n",
              "  'n07720875',\n",
              "  'n07579787',\n",
              "  'n02481823',\n",
              "  'n02364673',\n",
              "  'n04099969',\n",
              "  'n03662601',\n",
              "  'n02963159',\n",
              "  'n02231487',\n",
              "  'n02226429',\n",
              "  'n02699494',\n",
              "  'n02002724',\n",
              "  'n02268443',\n",
              "  'n03733131',\n",
              "  'n04486054',\n",
              "  'n07768694',\n",
              "  'n03796401',\n",
              "  'n04540053',\n",
              "  'n09246464',\n",
              "  'n02988304',\n",
              "  'n04328186',\n",
              "  'n04507155',\n",
              "  'n02892201',\n",
              "  'n07875152',\n",
              "  'n04371430',\n",
              "  'n03930313',\n",
              "  'n02423022',\n",
              "  'n04366367',\n",
              "  'n02837789',\n",
              "  'n04417672',\n",
              "  'n02395406',\n",
              "  'n02279972',\n",
              "  'n03937543',\n",
              "  'n01882714',\n",
              "  'n07871810',\n",
              "  'n02669723',\n",
              "  'n03544143',\n",
              "  'n03126707',\n",
              "  'n01629819',\n",
              "  'n04532106',\n",
              "  'n02795169',\n",
              "  'n04074963',\n",
              "  'n01698640',\n",
              "  'n03891332',\n",
              "  'n03706229',\n",
              "  'n01945685',\n",
              "  'n04008634',\n",
              "  'n02085620'],\n",
              " {'n03584254': 0,\n",
              "  'n04465501': 1,\n",
              "  'n02793495': 2,\n",
              "  'n03970156': 3,\n",
              "  'n06596364': 4,\n",
              "  'n02094433': 5,\n",
              "  'n03026506': 6,\n",
              "  'n03770439': 7,\n",
              "  'n04149813': 8,\n",
              "  'n03976657': 9,\n",
              "  'n07695742': 10,\n",
              "  'n03355925': 11,\n",
              "  'n04501370': 12,\n",
              "  'n02927161': 13,\n",
              "  'n03649909': 14,\n",
              "  'n04456115': 15,\n",
              "  'n04133789': 16,\n",
              "  'n03100240': 17,\n",
              "  'n04398044': 18,\n",
              "  'n03014705': 19,\n",
              "  'n02814860': 20,\n",
              "  'n03255030': 21,\n",
              "  'n02917067': 22,\n",
              "  'n02841315': 23,\n",
              "  'n01644900': 24,\n",
              "  'n04254777': 25,\n",
              "  'n04376876': 26,\n",
              "  'n03160309': 27,\n",
              "  'n07711569': 28,\n",
              "  'n04560804': 29,\n",
              "  'n02730930': 30,\n",
              "  'n02321529': 31,\n",
              "  'n03617480': 32,\n",
              "  'n02165456': 33,\n",
              "  'n09193705': 34,\n",
              "  'n02113799': 35,\n",
              "  'n04532670': 36,\n",
              "  'n02099601': 37,\n",
              "  'n01768244': 38,\n",
              "  'n04597913': 39,\n",
              "  'n02815834': 40,\n",
              "  'n02106662': 41,\n",
              "  'n07614500': 42,\n",
              "  'n02206856': 43,\n",
              "  'n02843684': 44,\n",
              "  'n07873807': 45,\n",
              "  'n09256479': 46,\n",
              "  'n02415577': 47,\n",
              "  'n09428293': 48,\n",
              "  'n02403003': 49,\n",
              "  'n03637318': 50,\n",
              "  'n02791270': 51,\n",
              "  'n02950826': 52,\n",
              "  'n07615774': 53,\n",
              "  'n03977966': 54,\n",
              "  'n02123045': 55,\n",
              "  'n07749582': 56,\n",
              "  'n02074367': 57,\n",
              "  'n01784675': 58,\n",
              "  'n02480495': 59,\n",
              "  'n02909870': 60,\n",
              "  'n07753592': 61,\n",
              "  'n02948072': 62,\n",
              "  'n02802426': 63,\n",
              "  'n03447447': 64,\n",
              "  'n02437312': 65,\n",
              "  'n03400231': 66,\n",
              "  'n02132136': 67,\n",
              "  'n04487081': 68,\n",
              "  'n01910747': 69,\n",
              "  'n02124075': 70,\n",
              "  'n02509815': 71,\n",
              "  'n04265275': 72,\n",
              "  'n02190166': 73,\n",
              "  'n04562935': 74,\n",
              "  'n02410509': 75,\n",
              "  'n03424325': 76,\n",
              "  'n04070727': 77,\n",
              "  'n04259630': 78,\n",
              "  'n03763968': 79,\n",
              "  'n07715103': 80,\n",
              "  'n04146614': 81,\n",
              "  'n02129165': 82,\n",
              "  'n03992509': 83,\n",
              "  'n02906734': 84,\n",
              "  'n03388043': 85,\n",
              "  'n04023962': 86,\n",
              "  'n03804744': 87,\n",
              "  'n01774384': 88,\n",
              "  'n03085013': 89,\n",
              "  'n03179701': 90,\n",
              "  'n01984695': 91,\n",
              "  'n07734744': 92,\n",
              "  'n02486410': 93,\n",
              "  'n04285008': 94,\n",
              "  'n03837869': 95,\n",
              "  'n04251144': 96,\n",
              "  'n04311004': 97,\n",
              "  'n03201208': 98,\n",
              "  'n01774750': 99,\n",
              "  'n03854065': 100,\n",
              "  'n02788148': 101,\n",
              "  'n02808440': 102,\n",
              "  'n03670208': 103,\n",
              "  'n01855672': 104,\n",
              "  'n01950731': 105,\n",
              "  'n07583066': 106,\n",
              "  'n03042490': 107,\n",
              "  'n01917289': 108,\n",
              "  'n02977058': 109,\n",
              "  'n01742172': 110,\n",
              "  'n01770393': 111,\n",
              "  'n01983481': 112,\n",
              "  'n02236044': 113,\n",
              "  'n01443537': 114,\n",
              "  'n02999410': 115,\n",
              "  'n02233338': 116,\n",
              "  'n02281406': 117,\n",
              "  'n02814533': 118,\n",
              "  'n02125311': 119,\n",
              "  'n02883205': 120,\n",
              "  'n03838899': 121,\n",
              "  'n07920052': 122,\n",
              "  'n03814639': 123,\n",
              "  'n07747607': 124,\n",
              "  'n03980874': 125,\n",
              "  'n02666196': 126,\n",
              "  'n03250847': 127,\n",
              "  'n03404251': 128,\n",
              "  'n02504458': 129,\n",
              "  'n02099712': 130,\n",
              "  'n02056570': 131,\n",
              "  'n04356056': 132,\n",
              "  'n03393912': 133,\n",
              "  'n02058221': 134,\n",
              "  'n09332890': 135,\n",
              "  'n03089624': 136,\n",
              "  'n04596742': 137,\n",
              "  'n04179913': 138,\n",
              "  'n03599486': 139,\n",
              "  'n04399382': 140,\n",
              "  'n01944390': 141,\n",
              "  'n04067472': 142,\n",
              "  'n02123394': 143,\n",
              "  'n03983396': 144,\n",
              "  'n01641577': 145,\n",
              "  'n02823428': 146,\n",
              "  'n12267677': 147,\n",
              "  'n03902125': 148,\n",
              "  'n03444034': 149,\n",
              "  'n04118538': 150,\n",
              "  'n04275548': 151,\n",
              "  'n02769748': 152,\n",
              "  'n07720875': 153,\n",
              "  'n07579787': 154,\n",
              "  'n02481823': 155,\n",
              "  'n02364673': 156,\n",
              "  'n04099969': 157,\n",
              "  'n03662601': 158,\n",
              "  'n02963159': 159,\n",
              "  'n02231487': 160,\n",
              "  'n02226429': 161,\n",
              "  'n02699494': 162,\n",
              "  'n02002724': 163,\n",
              "  'n02268443': 164,\n",
              "  'n03733131': 165,\n",
              "  'n04486054': 166,\n",
              "  'n07768694': 167,\n",
              "  'n03796401': 168,\n",
              "  'n04540053': 169,\n",
              "  'n09246464': 170,\n",
              "  'n02988304': 171,\n",
              "  'n04328186': 172,\n",
              "  'n04507155': 173,\n",
              "  'n02892201': 174,\n",
              "  'n07875152': 175,\n",
              "  'n04371430': 176,\n",
              "  'n03930313': 177,\n",
              "  'n02423022': 178,\n",
              "  'n04366367': 179,\n",
              "  'n02837789': 180,\n",
              "  'n04417672': 181,\n",
              "  'n02395406': 182,\n",
              "  'n02279972': 183,\n",
              "  'n03937543': 184,\n",
              "  'n01882714': 185,\n",
              "  'n07871810': 186,\n",
              "  'n02669723': 187,\n",
              "  'n03544143': 188,\n",
              "  'n03126707': 189,\n",
              "  'n01629819': 190,\n",
              "  'n04532106': 191,\n",
              "  'n02795169': 192,\n",
              "  'n04074963': 193,\n",
              "  'n01698640': 194,\n",
              "  'n03891332': 195,\n",
              "  'n03706229': 196,\n",
              "  'n01945685': 197,\n",
              "  'n04008634': 198,\n",
              "  'n02085620': 199})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "train_data = datasets.ImageFolder(root=\"tiny-imagenet-200/train\", # target folder of images\n",
        "                                  transform=ToTensor(), # transforms to perform on data (images)\n",
        "                                  target_transform=None) # transforms to perform on labels (if necessary)\n",
        "test_data = datasets.ImageFolder(root=\"tiny-imagenet-200/test\", # target folder of images\n",
        "                                  transform=ToTensor(), # transforms to perform on data (images)\n",
        "                                  target_transform=None) # transforms to perform on labels (if necessary)\n",
        "val_data = datasets.ImageFolder(root=\"tiny-imagenet-200/val\", # target folder of images\n",
        "                                  transform=ToTensor(), # transforms to perform on data (images)\n",
        "                                  target_transform=None) # transforms to perform on labels (if necessary)"
      ],
      "metadata": {
        "id": "In4ucYUFudTq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup the batch size hyperparameter\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# Turn datasets into iterables (batches)\n",
        "train_dataloader = DataLoader(train_data, # dataset to turn into iterable\n",
        "    batch_size=BATCH_SIZE, # how many samples per batch?\n",
        "    shuffle=True # shuffle data every epoch?\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(test_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False # don't necessarily have to shuffle the testing data\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(val_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False # don't necessarily have to shuffle the testing data\n",
        ")\n",
        "# Let's check out what we've created\n",
        "print(f\"Dataloaders: {train_dataloader, val_dataloader}\")\n",
        "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
        "print(f\"Length of val dataloader: {len(val_dataloader)} batches of {BATCH_SIZE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSr36Hr2xN4i",
        "outputId": "256b95b1-9ea3-4b2d-b45f-44b97fdc6991"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7a7745f7c910>, <torch.utils.data.dataloader.DataLoader object at 0x7a776c163790>)\n",
            "Length of train dataloader: 391 batches of 256\n",
            "Length of val dataloader: 40 batches of 256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# Your existing setup\n",
        "# model = ... ResNet18 ...\n",
        "# loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# 1. Define the optimizer (use a higher initial LR like the paper, e.g., 0.1)\n",
        "# Note: 0.01 is also a fine starting point for a smaller dataset like Tiny ImageNet.\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "# 2. Define the scheduler\n",
        "# This will decrease the LR by a factor of 10 at epoch 5 and epoch 8.\n",
        "scheduler = ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.1,\n",
        "    patience=5 # A common starting value; you may need to tune this\n",
        ")"
      ],
      "metadata": {
        "id": "_jsqlZrCupvv"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import accuracy_fn # Note: could also use torchmetrics.Accuracy(task = 'multiclass', num_classes=len(class_names)).to(device)\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "def print_train_time(start: float, end: float, device: torch.device = None):\n",
        "    \"\"\"Prints difference between start and end time.\n",
        "\n",
        "    Args:\n",
        "        start (float): Start time of computation (preferred in timeit format).\n",
        "        end (float): End time of computation.\n",
        "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        float: time between start and end in seconds (higher is longer).\n",
        "    \"\"\"\n",
        "    total_time = end - start\n",
        "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "    return total_time"
      ],
      "metadata": {
        "id": "uWn2mAloxT9d"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "from timeit import default_timer as timer\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Assuming model, loss_fn, optimizer, accuracy_fn, train_dataloader, test_dataloader, and device are defined\n",
        "\n",
        "# Set the seed and start the timer\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu = timer()\n",
        "\n",
        "# Define the learning rate scheduler as specified in the paper\n",
        "# It divides the learning rate by 10 (factor=0.1) when the error plateaus.\n",
        "# 'mode' is 'min' because we're monitoring validation loss.\n",
        "# 'patience' determines how many epochs to wait for improvement before reducing LR.\n",
        "# The paper doesn't specify patience, so a common starting value like 5 is used.\n",
        "scheduler = ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.1,\n",
        "    patience=5,\n",
        "    verbose=True # To see when the learning rate is adjusted\n",
        ")\n",
        "\n",
        "# ResNet paper trains for up to 60 * 10^4 iterations (mini-batches).\n",
        "# We'll set a high number of epochs and break the loop if iterations are met,\n",
        "# or let the scheduler reduce LR until convergence.\n",
        "# A typical ResNet training can take 90-120 epochs, but we'll adapt to iterations.\n",
        "max_iterations = 60 * 10**4\n",
        "current_iterations = 0\n",
        "epochs = 120 # Set a sufficiently high number of epochs to reach max_iterations or convergence\n",
        "\n",
        "# Create training and testing loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epoch}\\n-------\")\n",
        "    ### Training\n",
        "    train_loss = 0\n",
        "    model.train() # Set the model to training mode\n",
        "\n",
        "    # Add a loop to loop through training batches\n",
        "    for batch_idx, (X, y) in enumerate(train_dataloader):\n",
        "        # Break if max_iterations is reached\n",
        "        if current_iterations >= max_iterations:\n",
        "            print(f\"Reached max_iterations ({max_iterations}). Stopping training.\")\n",
        "            break\n",
        "\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate loss (per batch)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item() # Use .item() to get a standard Python number for summation\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        current_iterations += 1 # Increment iteration count\n",
        "\n",
        "        # Print out how many samples have been seen\n",
        "        if current_iterations % 1000 == 0: # Print less frequently to avoid spamming console\n",
        "            print(f\"Iteration: {current_iterations} | Looked at {batch_idx * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "    # If max_iterations was reached within the inner loop, break the outer loop too\n",
        "    if current_iterations >= max_iterations:\n",
        "        break\n",
        "\n",
        "    # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    ### Testing (Validation)\n",
        "    # Setup variables for accumulatively adding up loss and accuracy\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model.eval() # Set the model to evaluation mode\n",
        "    with torch.inference_mode():\n",
        "        for X, y in val_dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            # 1. Forward pass\n",
        "            test_pred = model(X)\n",
        "\n",
        "            # 2. Calculate loss (accumulatively)\n",
        "            test_loss += loss_fn(test_pred, y).item() # Use .item()\n",
        "\n",
        "            # 3. Calculate accuracy (preds need to be same as y_true)\n",
        "            test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "        # Calculations on test metrics need to happen inside torch.inference_mode()\n",
        "        # Divide total test loss by length of test dataloader (per batch)\n",
        "        test_loss /= len(val_dataloader)\n",
        "\n",
        "        # Divide total accuracy by length of test dataloader (per batch)\n",
        "        test_acc /= len(val_dataloader)\n",
        "\n",
        "    ## Print out what's happening\n",
        "    # Step the scheduler based on the validation loss (test_loss)\n",
        "    scheduler.step(test_loss)\n",
        "    current_lr = optimizer.param_groups[0]['lr'] # Get the current learning rate from the optimizer\n",
        "\n",
        "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%, Current LR: {current_lr:.6f}\\n\")\n",
        "    print(f\"Saving model at epoch {epoch} and iteration {current_iterations}...\")\n",
        "    torch.save(model.state_dict(), f\"model_epoch{epoch}_iter{current_iterations}.pth\")\n",
        "\n",
        "# Calculate training time\n",
        "train_time_end_on_cpu = timer()\n",
        "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
        "                                           end=train_time_end_on_cpu,\n",
        "                                           device=str(next(model.parameters()).device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e711b7b587bf4dcb86440e64ad603597",
            "6fe994f5622f45168c15eb53b849e749",
            "25d9c03484f749b8a570ca12aef9b6c4",
            "69f12f548f8e4eeead9ac082a1452c40",
            "d1ca2ad95ac64edda90491d62a213060",
            "155255fa65e44f50a1aed25778b20933",
            "d7f94f02117542b1a62d32eba9826bef",
            "7f80b12cfed744c4bf27840d7b787610",
            "3b419b5ddb2e4c7484907a4c5dd23100",
            "ed6b1596ad094870a2436d89e59a683b",
            "2dc2da9cb3c94a4381bc9580788fe744"
          ]
        },
        "id": "pF-N18K4wW5h",
        "outputId": "84500a13-5139-40e3-adf2-f815f015c27d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/120 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e711b7b587bf4dcb86440e64ad603597"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "-------\n",
            "\n",
            "Train loss: 0.02432 | Test loss: 17.02022, Test acc: 0.63%, Current LR: 0.010000\n",
            "\n",
            "Saving model at epoch 0 and iteration 391...\n",
            "Epoch: 1\n",
            "-------\n",
            "\n",
            "Train loss: 0.01496 | Test loss: 17.08986, Test acc: 0.62%, Current LR: 0.010000\n",
            "\n",
            "Saving model at epoch 1 and iteration 782...\n",
            "Epoch: 2\n",
            "-------\n",
            "Iteration: 1000 | Looked at 55552/100000 samples\n",
            "\n",
            "Train loss: 0.01231 | Test loss: 17.22180, Test acc: 0.59%, Current LR: 0.010000\n",
            "\n",
            "Saving model at epoch 2 and iteration 1173...\n",
            "Epoch: 3\n",
            "-------\n",
            "\n",
            "Train loss: 0.01127 | Test loss: 17.18932, Test acc: 0.61%, Current LR: 0.010000\n",
            "\n",
            "Saving model at epoch 3 and iteration 1564...\n",
            "Epoch: 4\n",
            "-------\n",
            "\n",
            "Train loss: 0.01003 | Test loss: 17.26799, Test acc: 0.61%, Current LR: 0.010000\n",
            "\n",
            "Saving model at epoch 4 and iteration 1955...\n",
            "Epoch: 5\n",
            "-------\n",
            "Iteration: 2000 | Looked at 11264/100000 samples\n",
            "\n",
            "Train loss: 0.00922 | Test loss: 17.38690, Test acc: 0.59%, Current LR: 0.010000\n",
            "\n",
            "Saving model at epoch 5 and iteration 2346...\n",
            "Epoch: 6\n",
            "-------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2389878661.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Add a loop to loop through training batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Break if max_iterations is reached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcurrent_iterations\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \"\"\"\n\u001b[1;32m    244\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    984\u001b[0m             \u001b[0mdeprecate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0mhas_transparency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"transparency\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}